---
layout: post
title: "Large Graph Model to Condense Knowledge and Logics"
subtitle: ""
date: 2023-05-23
author: "Jamin Chen"
header-img: "img/post-bg-universe.jpg"
tags: ["Sapientia", "LLM"]
---

## Background

The core of a knowledge computing engine lies at an efficient and computational
representation of knowledge/logics. This requirement is also one of vital pieces
of future artificial general intelligence (AGI). Recent success of Transformer
in natural language field, especially with Large Language Models like GPT-4 and
LLaMA series, inspires us that neural networks (NNs) with Attention mechanism
are efficient at condensing information and logics encoded in sequential tokens
[?]. However these models still remain as black box to uncover the inner
representation of learned knowledge. The main reason comes from the token
vectorization and high dimensional nature of neural networks with a vast amount
(tens to hundreds of billions) of parameters and deep layers.

We can imagine there is a higher dimensional space that absorbs and masters the
token occurrence patterns as vectors, also with their computational relations as
complex logics. Nevertheless we encounter a challenge to interpret, extract and
reuse those mastered patterns as explicit knowledge outside a trained model. The
representation of specific knowledge piece or logical relation remains varying
as for training context changes, neural network structures, and a bulk of
fine-tuning techniques. The models trained by different people, even a group of
models trained with the same datasets at different times are isolated and
unstable when considering their inner representations.

A portion of community endeavor is put into reversing engineering the black box
by prompt engineering [?], single neuron semantics interpretation [?],
theoretical mirroring structural analysis [?] etc. We argue that the first
principle thinking should be used to derive the basic and core problem about
what we are talking about knowledge representation. What is the most straight
forward way to represent knowledge? The answer is proposed as "symbolic". We
human race gained the capability to exchange information and relay history from
generation to generation as for the invention of symbolic expression, which also
enhances our logical reasoning under the help of symbolically driven inner voice
[?]. Hence the symbolic is a native way of knowledge representation. 

## Knowledge Representation

Hypothesis: LLM illustrates the capability to absorb world knowledge as well as
reasonable logics, because it masters not the world knowledge per se, but the
rule of knowledge expression (in symbolic natural language).

* Disadvantages of knowledge in NL
* Hypergraph enabled
* Natural integration of cognitive and actionable knowledge?

## Generative Graphical Patterns

* Large Graph Model

## A General Framework towards LGM
NL -> klang (hypergraph enhanced) -> LGM -> klang -> NL

## How To Engineer LGM

## Future

## References

[1] Ektefaie, Y., Dasoulas, G., Noori, A. et al. Multimodal learning with graphs. Nat Mach Intell 5, 340â€“350 (2023). https://doi.org/10.1038/s42256-023-00624-6
