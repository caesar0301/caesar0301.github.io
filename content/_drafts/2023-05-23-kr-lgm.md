---
layout: post
title: "Knowledge Representation and Large Graph Models"
subtitle: ""
date: 2023-05-23
author: "Jamin Chen"
header-img: "img/post-bg-universe.jpg"
tags: ["Sapientia", "LLM"]
---

## Background

The core of a knowledge computing engine lies at an efficient and computational
representation of knowledge/logics. This requirement is also one of vital pieces
of future artificial general intelligence (AGI). Recent success of Transformer
in natural language field, especially with Large Language Models like GPT-4 and
LLaMA series, inspires us that neural networks (NNs) with Attention mechanism
are efficient at condensing information and logics encoded in sequential tokens
[?]. However these models still remain as black box to uncover the inner
representation of learned knowledge. The main reason comes from the token
vectorization and high dimensional nature of neural networks with a vast amount
(tens to hundreds of billions) of parameters and deep layers.

We can imagine there is a higher dimensional space that absorbs and masters the
token occurrence patterns as vectors, also with their computational relations as
complex logics. Nevertheless we encounter a challenge to interpret, extract and
reuse those mastered patterns as explicit knowledge outside a trained model. The
representation of specific knowledge piece or logical relation remains varying
as for training context changes, neural network structures, and a bulk of
fine-tuning techniques. The models trained by different people, even a group of
models trained with the same datasets at different times are isolated and
unstable when considering their inner representations.

**Hypothesis-1**. LLM illustrates the capability to absorb world knowledge as
well as reasonable logics, because it masters not the world knowledge per se,
but the rules of knowledge organization in natural languages.

A portion of community endeavor is put into reversing engineering the black box
by prompt engineering [?], single neuron interpretation [?], network structural
analysis [?] etc. We argue that the first principle thinking should be used to
derive the basic and core problem about what we are talking about knowledge
representation (KR). What is the most straight forward way to represent
knowledge? The answer is proposed as "symbolic". Human have gained the
capability to exchange information and relay history from generation to
generation as for the invention of symbolic expression, which also enhances our
logical reasoning under the help of symbolically (usually by native language)
driven inner voice [?]. Hence the symbolic is still the native way of knowledge
representation.

## Limitations of LLM in KR

We have accumulated a large amount of knowledge in different forms, while the
symbolic conveys a significant portion. The symbolic is a convenient way to
communicate in speaking and writing. What LLM captures well is the patterns of
symbol sequences in which grammar and logics are encoded. Nevertheless there are
other forms of important symbolic knowledge, such as arithmetic equations, that
LLM can not deal well with. Many experiments have shown that LLM fails to
calculate addition and multiplication of arbitrary large numbers, much less
complicated mathematical theorem understanding. The core reason is that the
symbol 'plus' or '+' is not just a token in a sample sequence, but also with
calculating rules as predefined in math. A sequential regression model which
heavily relies on sample occurrences can not master this kind of implicit
knowledge well. In the natural language scenario, we are always surprised by the
knowledge scale and grammatical generation of LLM, while ignoring that there are
substantial related samples in the training datasets. Another explanation for
the weaknesses of LLM in arithmetic calculation is because we can not have a
training dataset contains a full enumeration of the symbolic calculation, except
for a specialized preparation.

**Hypothesis-2**. LLM presents superb capabilities in pattern capturing and
summarization, while showing an intrinsic weakness to involve the encoded
implicit knowledge in symbols.

##  General Principles of KR

For general concept of knowledge, interpretation, reusability and integration
are the basic practicable demands in our daily life. In a similar sense,
knowledge representation in cognitive computing or AGI systems should also
possess these natures. Concretely,

* Interpretation, foundation stone for explainable knowledge systems. We could
    trace the source and reasoning process for specific conclusion. It is the
    vital part to construct paradigm of knowledge discovery, differing from
    knowledge squeezing and summarization, Hypothesis-1.

* Reusability, transferring summarized or discovered knowledge ingredients
    across different artificial intelligent systems. In LLM, we assume that
    complex relational dependencies between explicit knowledge ingredients are
    fetched, as some neural pathways created in creatural brains, being locked
    as black-boxed representations.

* Integration, exemplified as some kind of 'knowledge protocol' between
    systems. Almost every branch of our theories owns a suite of symbol
    framework to present its assumptions, axioms, theorems, deductions etc., for
    both precise communication and interaction with other frameworks.

## Knowledge Intermediate Representation

To address the challenges observed in LLMs, we suggest that knowledge
representation should be separated from communication and reasoning processes
and propose a concept of Knowledge Intermediate Representation (KIR) to fulfill
above principles. Some explicit and flexible structures, for example hypergraph,
are preferred for KIR. Recent progress in multimodal graph learning field [1]
also confirms the importance and powerfulness of selecting a suitable
presentation paradigm in a multimodal learning sense.

![road graph](/img/inpost/2023/KIR-LGM.png)


## Generative Graph Patterns

* Large Graph Model

## A General Framework towards LGM

NL -> klang (hypergraph enhanced) -> LGM -> klang -> NL

## How To Engineer LGM

## Future

## References

[1] Ektefaie, Y., Dasoulas, G., Noori, A. et al. Multimodal learning with
graphs. Nat Mach Intell 5, 340â€“350 (2023).
https://doi.org/10.1038/s42256-023-00624-6
